{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Семинар 24.09 - про рекурсию и парсинг сайтов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Рекурсия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Рекурсивная функция - это функция, которая вызывает сому себя\n",
    "# f(n) = n*f(n-1) - рекуррентное соотношение\n",
    "\n",
    "\n",
    "def factorial(n):\n",
    "    return n * factorial(n-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "ename": "RecursionError",
     "evalue": "maximum recursion depth exceeded",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRecursionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-97-b331b9ab0f2d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#что будет?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mfactorial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-96-9fa89bfa538c>\u001b[0m in \u001b[0;36mfactorial\u001b[0;34m(n)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfactorial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mfactorial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "... last 1 frames repeated, from the frame below ...\n",
      "\u001b[0;32m<ipython-input-96-9fa89bfa538c>\u001b[0m in \u001b[0;36mfactorial\u001b[0;34m(n)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfactorial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mfactorial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRecursionError\u001b[0m: maximum recursion depth exceeded"
     ]
    }
   ],
   "source": [
    "#что будет?\n",
    "\n",
    "factorial(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def factorial(n):\n",
    "    if not n:\n",
    "        return 1\n",
    "    return n * factorial(n+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-5040"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "factorial(-7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Парсинг сайтов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "def download_from_the_internet(url):\n",
    "    try:\n",
    "        return urlopen(url).read()\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "    \n",
    "url = 'https://simple.wikipedia.org/wiki/Main_Page'\n",
    "html = download_from_the_internet(url)\n",
    "print(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urldefrag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "# документация\n",
    "# https://www.crummy.com/software/BeautifulSoup/bs4/doc/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = BeautifulSoup(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<title>Wikipedia</title>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'title'"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.title.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Найти ссылки можно по тегу a\n",
    "parser.find_all('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Все ссылки можно получить (из документации)\n",
    "for link in parser.find_all('a'):\n",
    "    print(link.get('href'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как отфильтровать реальные ссылки?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://cat.com/list;meow?breed=siberian\n",
    "\n",
    "https is the scheme (first element of a URL)\n",
    "cat.com is the netloc (sits between the scheme and path)\n",
    "/list is the path (between the netloc and params)\n",
    "meow is the param (sits between path and query)\n",
    "breed=siberian is the query (between the fragment and params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParseResult(scheme='https', netloc='cat.com', path='/list', params='', query='', fragment='')"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urlparse('https://cat.com/list')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 1 - Рекурсивный обход википедии (6 баллов)\n",
    "\n",
    "1) Начиная со страницы (уровень рекурсии 0) https://simple.wikipedia.org/wiki/Main_Page вам необходимо распарсить все ссылки на этой странице, выбрать все ссылки, относящиеся к simple.wikipedia.org \n",
    "(имеющие netloc == 'simple.wikipedia.org' либо netloc == '' - относительные ссылки на страницу) и сохранить их в виде списка\n",
    "\n",
    "2) Далее, рекурсивно для каждой из полученных ссылок повторить алгоритм (грузим страницу по ссылке, парсим все ссылки на странице, сохраняем в виде списка), обозначим этот вызов как рекурсия глубины 1.\n",
    "\n",
    "3) Ваша задача - остановиться на рекурсии глубины 10, в качестве ответа на задачу - нужно вернуть список ссылок, сколько их у вас получилось?\n",
    "\n",
    "Глобальными переменными пользоваться запрещено, передаем текущий уровень и список(или set) как аргументы функции!!!\n",
    "\n",
    "Замечание - если вы уже встречали ссылку ранее, проходить по ней еще раз не нужно\n",
    "\n",
    "\n",
    "4) Задание оформить в виде файла с названием lastname_seminar6.py, в нем должна быть функция, которая принимает на вход ссылку, текущую глубину и уже пройденные ссылки (см ниже пример функции recursive_calls), допустимо использование вспомогательных функций, но запрещены глобальные переменные"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Что такое относительная ссылка?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://simple.wikipedia.org/w/index.php?title=Main_Page&oldid=7731071 ParseResult(scheme='https', netloc='simple.wikipedia.org', path='/w/index.php', params='', query='title=Main_Page&oldid=7731071', fragment='')\n",
      "//simple.wikipedia.org/wiki/Wikipedia:Contact_us ParseResult(scheme='', netloc='simple.wikipedia.org', path='/wiki/Wikipedia:Contact_us', params='', query='', fragment='')\n",
      "//simple.wikipedia.org/wiki/Wikipedia:Text_of_Creative_Commons_Attribution-ShareAlike_3.0_Unported_License ParseResult(scheme='', netloc='simple.wikipedia.org', path='/wiki/Wikipedia:Text_of_Creative_Commons_Attribution-ShareAlike_3.0_Unported_License', params='', query='', fragment='')\n",
      "//simple.wikipedia.org/wiki/Wikipedia:Text_of_the_GNU_Free_Documentation_License ParseResult(scheme='', netloc='simple.wikipedia.org', path='/wiki/Wikipedia:Text_of_the_GNU_Free_Documentation_License', params='', query='', fragment='')\n"
     ]
    }
   ],
   "source": [
    "for link in parser.find_all('a'):\n",
    "    href = link.get('href')\n",
    "    parsed_href = urlparse(href)\n",
    "    # проверяем что ссылка куда-то ведет\n",
    "    if parsed_href.netloc == 'simple.wikipedia.org' and parsed_href.path: \n",
    "        print(href, urlparse(href))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Тут мы видим относительную ссылку\n",
    "for link in parser.find_all('a'):\n",
    "    href = link.get('href')\n",
    "    parsed_href = urlparse(href)\n",
    "    \n",
    "    if not parsed_href.netloc and parsed_href.path:\n",
    "        print(href, urlparse(href))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для того, чтобы наша ссылка была чистой, и мы могли понимать, встречали ли мы ее ранее, нам нужно избавиться от дополнительных параметров ссылки (params, query, fragment)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://simple.wikipedia.org/wiki/test'"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urljoin('https://simple.wikipedia.org/wiki/Main_Page', '/wiki/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urljoin\n",
    "\n",
    "start_page = 'https://simple.wikipedia.org/wiki/Main_Page'\n",
    "a\n",
    "for link in parser.find_all('a'):\n",
    "    href = link.get('href')\n",
    "    parsed_href = urlparse(href)\n",
    "    \n",
    "    if not parsed_href.netloc and parsed_href.path:\n",
    "        # чистые ссылки\n",
    "        print(urljoin(start_page, parsed_href.path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Как должен выглядеть ваш метод, решающий задачу?\n",
    "\n",
    "\n",
    "def recursive_calls(current_link, depth, visited_links):\n",
    "    if depth >= 10:\n",
    "        return\n",
    "    \n",
    "    links_from_the_page = your_function(current_link)\n",
    "    \n",
    "    ...\n",
    "    \n",
    "    for new_link in ...:\n",
    "        sleep(1)\n",
    "        recursive_calls(new_link, depth+1, visited_links)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Про библиотеку selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting selenium\n",
      "  Using cached selenium-3.141.0-py2.py3-none-any.whl (904 kB)\n",
      "Requirement already satisfied: urllib3 in /usr/local/lib/python3.9/site-packages (from selenium) (1.26.2)\n",
      "Installing collected packages: selenium\n",
      "Successfully installed selenium-3.141.0\n"
     ]
    }
   ],
   "source": [
    "!pip3 install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting webdriver-manager\n",
      "  Downloading webdriver_manager-3.4.2-py2.py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.9/site-packages (from webdriver-manager) (2.25.0)\n",
      "Collecting configparser\n",
      "  Downloading configparser-5.0.2-py3-none-any.whl (19 kB)\n",
      "Collecting crayons\n",
      "  Downloading crayons-0.4.0-py2.py3-none-any.whl (4.6 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/site-packages (from requests->webdriver-manager) (2020.11.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/site-packages (from requests->webdriver-manager) (1.26.2)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/site-packages (from requests->webdriver-manager) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.9/site-packages (from requests->webdriver-manager) (3.0.4)\n",
      "Collecting colorama\n",
      "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
      "Installing collected packages: configparser, colorama, crayons, webdriver-manager\n",
      "Successfully installed colorama-0.4.4 configparser-5.0.2 crayons-0.4.0 webdriver-manager-3.4.2\n"
     ]
    }
   ],
   "source": [
    "!pip3 install webdriver-manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "INFO:WDM:\n",
      "\n",
      "====== WebDriver manager ======\n",
      "INFO:WDM:====== WebDriver manager ======\n",
      "Current google-chrome version is 94.0.4606\n",
      "INFO:WDM:Current google-chrome version is 94.0.4606\n",
      "Get LATEST driver version for 94.0.4606\n",
      "INFO:WDM:Get LATEST driver version for 94.0.4606\n",
      "Get LATEST driver version for 94.0.4606\n",
      "INFO:WDM:Get LATEST driver version for 94.0.4606\n",
      "Trying to download new driver from https://chromedriver.storage.googleapis.com/94.0.4606.41/chromedriver_mac64.zip\n",
      "INFO:WDM:Trying to download new driver from https://chromedriver.storage.googleapis.com/94.0.4606.41/chromedriver_mac64.zip\n",
      "Driver has been saved in cache [/Users/pogodina-eval/.wdm/drivers/chromedriver/mac64/94.0.4606.41]\n",
      "INFO:WDM:Driver has been saved in cache [/Users/pogodina-eval/.wdm/drivers/chromedriver/mac64/94.0.4606.41]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://simple.wikipedia.org/wiki/Main_Page\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import time\n",
    "\n",
    "\n",
    "# driver = webdriver.Chrome()\n",
    "\n",
    "# если не работает - то так\n",
    "driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "\n",
    "driver.get('https://simple.wikipedia.org/wiki/Main_Page')\n",
    "\n",
    "print(driver.current_url)\n",
    "#https://selenium-python.readthedocs.io/locating-elements.html\n",
    "element = driver.find_element_by_partial_link_text('Hermann')\n",
    "element.click()\n",
    "\n",
    "search_element = driver.find_element_by_name('search')\n",
    "search_element.send_keys('test')\n",
    "search_element.send_keys(webdriver.common.keys.Keys.ENTER)\n",
    "time.sleep(5)\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 2 - 4 балла\n",
    "\n",
    "1) Найти любую статью из предыдущего задания, которую вы добавили на 10-м уровне рекурсии (нужно написать новую функцию find_link_from_10_depth)\n",
    "\n",
    "2) с помощью библиотеки selenium нужно начиная с главной страницы (https://simple.wikipedia.org/wiki/Main_Page) перейти на эту статью \n",
    "\n",
    "это можно сделать двумя способами:\n",
    "- найти путь (это сделать можно внутри функции find_link_from_10_depth) от главной страницы  до этой статьи и последовательно переходить по страницам\n",
    "- с помощью input ('search') вбить название этой статьи и перейти на нее\n",
    "\n",
    "3) задание должно быть оформлено в виде функции selenium_run(start_url, end_url), которая принимает на вход 2 ссылки - стартовая ссылка и финальная ссылка; перед завершением работы программы вы должны убедиться, что ваш driver находится на странице end_url (driver.current_url == end_url)\n",
    "\n",
    "\n",
    "Замечание 1 - написанные две функции можно сохранять в том же файле\n",
    "Замечание 2- вы не должны пользоваться информацией о том, что за статья на 10-м уровне (то есть вы не знаете ее название - вам нужно алгоритмически его получить) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selenium_run(start_url, end_url, way_from_start=None):\n",
    "    '''\n",
    "    way_from_start - необязательный аргумент, актуален если вы восопльзовались способом 'прокликать' ссылки от начала до конца\n",
    "    '''\n",
    "    driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "\n",
    "    driver.get(start_url)\n",
    "    \n",
    "    ...\n",
    "    # чтобы убедиться что вы там, где надо\n",
    "    driver.sleep(10)\n",
    "    if end_url != driver.current_url:\n",
    "        print('Oh no!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Дедлайн по заданиям - 29.09 23:59"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
