{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Семинар 24.09 - про рекурсию и парсинг сайтов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Рекурсия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Рекурсивная функция - это функция, которая вызывает сому себя\n",
    "# f(n) = n*f(n-1) - рекуррентное соотношение\n",
    "\n",
    "\n",
    "def factorial(n):\n",
    "    return n * factorial(n-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#что будет?\n",
    "\n",
    "factorial(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def factorial(n):\n",
    "    ...\n",
    "    return n * factorial(n-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "factorial(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Парсинг сайтов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "def download_from_the_internet(url):\n",
    "    try:\n",
    "        return urlopen(url).read()\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "    \n",
    "url = 'https://simple.wikipedia.org/wiki/Main_Page'\n",
    "html = download_from_the_internet(url)\n",
    "print(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urldefrag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "# документация\n",
    "# https://www.crummy.com/software/BeautifulSoup/bs4/doc/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = BeautifulSoup(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<title>Wikipedia</title>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'title'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.title.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Найти ссылки можно по тегу a\n",
    "parser.find_all('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Все ссылки можно получить (из документации)\n",
    "for link in parser.find_all('a'):\n",
    "    print(link.get('href'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как отфильтровать реальные ссылки?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://cat.com/list;meow?breed=siberian\n",
    "\n",
    "https is the scheme (first element of a URL)\n",
    "cat.com is the netloc (sits between the scheme and path)\n",
    "/list is the path (between the netloc and params)\n",
    "meow is the param (sits between path and query)\n",
    "breed=siberian is the query (between the fragment and params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParseResult(scheme='https', netloc='cat.com', path='/list', params='meow', query='breed=siberian', fragment='')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urlparse('https://cat.com/list;meow?breed=siberian')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 1 - Рекурсивный обход википедии (6 баллов)\n",
    "\n",
    "1) Начиная со страницы (уровень рекурсии 0) https://simple.wikipedia.org/wiki/Main_Page вам необходимо распарсить все ссылки на этой странице, выбрать все ссылки, относящиеся к simple.wikipedia.org \n",
    "(имеющие netloc == 'simple.wikipedia.org' либо netloc == '' - относительные ссылки на страницу) и сохранить их в виде списка\n",
    "\n",
    "2) Далее, рекурсивно для каждой из полученных ссылок повторить алгоритм (грузим страницу по ссылке, парсим все ссылки на странице, сохраняем в виде списка), обозначим этот вызов как рекурсия глубины 1.\n",
    "\n",
    "3) Ваша задача - остановиться на рекурсии глубины 10, в качестве ответа на задачу - нужно вернуть список ссылок, сколько их у вас получилось?\n",
    "\n",
    "Глобальными переменными пользоваться запрещено, передаем текущий уровень и список(или set) как аргументы функции!!!\n",
    "\n",
    "Замечание - если вы уже встречали ссылку ранее, проходить по ней еще раз не нужно\n",
    "\n",
    "\n",
    "4) Задание оформить в виде файла с названием lastname_seminar6.py, в нем должна быть функция, которая принимает на вход ссылку, текущую глубину и уже пройденные ссылки (см ниже пример функции recursive_calls), допустимо использование вспомогательных функций, но запрещены глобальные переменные"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Что такое относительная ссылка?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for link in parser.find_all('a'):\n",
    "    href = link.get('href')\n",
    "    parsed_href = urlparse(href)\n",
    "    # проверяем что ссылка куда-то ведет\n",
    "    if parsed_href.netloc == 'simple.wikipedia.org' and parsed_href.path: \n",
    "        print(href, urlparse(href))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Тут мы видим относительную ссылку\n",
    "for link in parser.find_all('a'):\n",
    "    href = link.get('href')\n",
    "    parsed_href = urlparse(href)\n",
    "    \n",
    "    if not parsed_href.netloc and parsed_href.path:\n",
    "        print(href, urlparse(href))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для того, чтобы наша ссылка была чистой, и мы могли понимать, встречали ли мы ее ранее, нам нужно избавиться от дополнительных параметров ссылки (params, query, fragment)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urljoin\n",
    "\n",
    "start_page = 'https://simple.wikipedia.org/wiki/Main_Page'\n",
    "\n",
    "for link in parser.find_all('a'):\n",
    "    href = link.get('href')\n",
    "    parsed_href = urlparse(href)\n",
    "    \n",
    "    if not parsed_href.netloc and parsed_href.path:\n",
    "        # чистые ссылки\n",
    "        print(urljoin(start_page, parsed_href.path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Как должен выглядеть ваш метод, решающий задачу?\n",
    "\n",
    "\n",
    "def recursive_calls(current_link, depth, visited_links):\n",
    "    if depth >= 10:\n",
    "        return\n",
    "    \n",
    "    links_from_the_page = your_function(current_link)\n",
    "    \n",
    "    ...\n",
    "    \n",
    "    for new_link in ...:\n",
    "        recursive_calls(new_link, depth+1, visited_links)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Про библиотеку selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting selenium\n",
      "  Using cached selenium-3.141.0-py2.py3-none-any.whl (904 kB)\n",
      "Requirement already satisfied: urllib3 in /usr/local/lib/python3.9/site-packages (from selenium) (1.26.2)\n",
      "Installing collected packages: selenium\n",
      "Successfully installed selenium-3.141.0\n"
     ]
    }
   ],
   "source": [
    "!pip3 install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting webdriver-manager\n",
      "  Downloading webdriver_manager-3.4.2-py2.py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.9/site-packages (from webdriver-manager) (2.25.0)\n",
      "Collecting configparser\n",
      "  Downloading configparser-5.0.2-py3-none-any.whl (19 kB)\n",
      "Collecting crayons\n",
      "  Downloading crayons-0.4.0-py2.py3-none-any.whl (4.6 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/site-packages (from requests->webdriver-manager) (2020.11.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/site-packages (from requests->webdriver-manager) (1.26.2)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/site-packages (from requests->webdriver-manager) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.9/site-packages (from requests->webdriver-manager) (3.0.4)\n",
      "Collecting colorama\n",
      "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
      "Installing collected packages: configparser, colorama, crayons, webdriver-manager\n",
      "Successfully installed colorama-0.4.4 configparser-5.0.2 crayons-0.4.0 webdriver-manager-3.4.2\n"
     ]
    }
   ],
   "source": [
    "!pip3 install webdriver-manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "INFO:WDM:\n",
      "\n",
      "====== WebDriver manager ======\n",
      "INFO:WDM:====== WebDriver manager ======\n",
      "Current google-chrome version is 94.0.4606\n",
      "INFO:WDM:Current google-chrome version is 94.0.4606\n",
      "Get LATEST driver version for 94.0.4606\n",
      "INFO:WDM:Get LATEST driver version for 94.0.4606\n",
      "Driver [/Users/pogodina-eval/.wdm/drivers/chromedriver/mac64/94.0.4606.41/chromedriver] found in cache\n",
      "INFO:WDM:Driver [/Users/pogodina-eval/.wdm/drivers/chromedriver/mac64/94.0.4606.41/chromedriver] found in cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://simple.wikipedia.org/wiki/Main_Page\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import time\n",
    "\n",
    "\n",
    "# driver = webdriver.Chrome()\n",
    "\n",
    "# если не работает - то так\n",
    "driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "\n",
    "driver.get('https://simple.wikipedia.org/wiki/Main_Page')\n",
    "\n",
    "print(driver.current_url)\n",
    "#https://selenium-python.readthedocs.io/locating-elements.html\n",
    "element = driver.find_element_by_partial_link_text('Hermann')\n",
    "element.click()\n",
    "\n",
    "search_element = driver.find_element_by_name('search')\n",
    "search_element.send_keys('test')\n",
    "search_element.send_keys(webdriver.common.keys.Keys.ENTER)\n",
    "time.sleep(5)\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 2 - 4 балла\n",
    "\n",
    "1) Найти любую статью из предыдущего задания, которую вы добавили на 10-м уровне рекурсии (нужно написать новую функцию find_link_from_10_depth)\n",
    "\n",
    "2) с помощью библиотеки selenium нужно начиная с главной страницы (https://simple.wikipedia.org/wiki/Main_Page) перейти на эту статью \n",
    "\n",
    "это можно сделать двумя способами:\n",
    "- найти путь (это сделать можно внутри функции find_link_from_10_depth) от главной страницы  до этой статьи и последовательно переходить по страницам\n",
    "- с помощью input ('search') вбить название этой статьи и перейти на нее\n",
    "\n",
    "3) задание должно быть оформлено в виде функции selenium_run(start_url, end_url), которая принимает на вход 2 ссылки - стартовая ссылка и финальная ссылка; перед завершением работы программы вы должны убедиться, что ваш driver находится на странице end_url (driver.current_url == end_url)\n",
    "\n",
    "\n",
    "Замечание 1 - написанные две функции можно сохранять в том же файле\n",
    "Замечание 2- вы не должны пользоваться информацией о том, что за статья на 10-м уровне (то есть вы не знаете ее название - вам нужно алгоритмически его получить) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selenium_run(start_url, end_url, way_from_start=None):\n",
    "    '''\n",
    "    way_from_start - необязательный аргумент, актуален если вы восопльзовались способом 'прокликать' ссылки от начала до конца\n",
    "    '''\n",
    "    driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "\n",
    "    driver.get(start_url)\n",
    "    \n",
    "    ...\n",
    "    # чтобы убедиться что вы там, где надо\n",
    "    driver.sleep(10)\n",
    "    if end_url != driver.current_url:\n",
    "        print('Oh no!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Дедлайн по заданиям - 29.09 23:59"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
